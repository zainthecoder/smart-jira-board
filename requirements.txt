# Core dependencies for Llama 3 8B inference
transformers>=4.40.0
torch>=2.2.0
accelerate>=0.28.0
sentencepiece>=0.2.0
protobuf>=4.25.0

# Optional but recommended for optimization
bitsandbytes>=0.43.0  # For quantization (8-bit/4-bit inference)
scipy>=1.12.0

# Development and utilities
python-dotenv>=1.0.0
pydantic>=2.6.0
pydantic-settings>=2.2.0


